# =============================================================================
# OpenClaw local deployment – environment variables
# =============================================================================
# 1) Copy to .env:    cp .env.example .env
#    Or run:           ./scripts/bootstrap.sh
# 2) Fill in values.  Only OPENCLAW_SRC_DIR and one LLM key are required.
# 3) Never commit .env – it is git-ignored.
# =============================================================================

# -----------------------------------------------------------------------------
# Build / source
# -----------------------------------------------------------------------------
# Absolute path to the openclaw git checkout on the host.
OPENCLAW_SRC_DIR=/home/you/Developer/openclaw

# -----------------------------------------------------------------------------
# Gateway auth
# -----------------------------------------------------------------------------
# Auto-generated by scripts/bootstrap.sh — leave blank to skip auth.
OPENCLAW_GATEWAY_TOKEN=

# Alternative: password auth (use token OR password, not both).
# OPENCLAW_GATEWAY_PASSWORD=

# -----------------------------------------------------------------------------
# Host port (container always listens on 18789 internally)
# -----------------------------------------------------------------------------
OPENCLAW_HOST_PORT=3210

# -----------------------------------------------------------------------------
# LLM provider API keys  (set at least one)
# -----------------------------------------------------------------------------
ANTHROPIC_API_KEY=
OPENAI_API_KEY=
GEMINI_API_KEY=

# Rotation / multi-key support
# OPENAI_API_KEYS=sk-1,sk-2
# ANTHROPIC_API_KEYS=sk-ant-1,sk-ant-2

# OpenRouter (aggregates many providers — good for cost optimization)
# OPENROUTER_API_KEY=

# -----------------------------------------------------------------------------
# Local / self-hosted LLM  (OpenAI-compatible endpoint)
# -----------------------------------------------------------------------------
# Point OpenClaw at a local vLLM, Ollama, or llama.cpp server.
# See README § "Local LLM" for details.
#
# OLLAMA_API_BASE=http://host.docker.internal:11434
# OLLAMA_API_KEY=not-needed

# -----------------------------------------------------------------------------
# Channels  (optional – set only what you use)
# -----------------------------------------------------------------------------
# TELEGRAM_BOT_TOKEN=
# TELEGRAM_CHAT_ID=
# DISCORD_BOT_TOKEN=
# SLACK_BOT_TOKEN=
# SLACK_APP_TOKEN=

# -----------------------------------------------------------------------------
# Tools & search  (optional)
# -----------------------------------------------------------------------------
# BRAVE_API_KEY=           # Free tier: 1,000 queries/month
# PERPLEXITY_API_KEY=
# FIRECRAWL_API_KEY=
# ELEVENLABS_API_KEY=
# DEEPGRAM_API_KEY=

# -----------------------------------------------------------------------------
# Observer / Admin bot  (optional — separate from the agent's main bot)
# -----------------------------------------------------------------------------
# The observer watchdog sends alerts to a SEPARATE Telegram bot so the agent
# cannot interfere with security notifications.
# OBSERVER_TELEGRAM_BOT_TOKEN=
# OBSERVER_TELEGRAM_CHAT_ID=
# OBSERVER_MODEL=qwen2.5:14b
# OBSERVER_AUTO_LOCKDOWN=true
